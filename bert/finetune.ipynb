{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules and Data\n",
    "BERT can be fine-tined on Stanford Sentiment Treebank-2(SST2) dataset for text classification task. More info about SST2 can be found [here](https://huggingface.co/datasets/stanfordnlp/sst2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'sst2' at /root/.cache/huggingface/datasets/glue/sst2/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Feb  5 17:36:25 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, AdamW\n",
    "from data import load_data\n",
    "from modules.optim_schedule import ScheduledOptim\n",
    "from modules.bert import BERTTextClassifier\n",
    "import config \n",
    "# load sst-2\n",
    "tokenizer, train_dataloader, valid_dataloader = load_data(\n",
    "    name=\"sst2\",\n",
    "    loading_ratio=1,  # 加载100%的数据\n",
    "    num_proc=4,  # 使用4个进程进行处理\n",
    "    splits=[\"train\", \"validation\"]  # load train and valid dataset\n",
    ")\n",
    "\n",
    "# check one batch\n",
    "for batch in train_dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    print(input_ids.shape, attention_mask.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Model and Load from Pre-trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a BERT text classification model which inherits from the BERT class and add a binary linear classification layer at the end of the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 108.89M\n",
      "BERTTextClassifier(\n",
      "  (embedding): BERTEmbedding(\n",
      "    (token): TokenEmbedding(30522, 768, padding_idx=0)\n",
      "    (position): PositionalEmbedding(512, 768)\n",
      "    (segment): SegmentEmbedding(2, 768, padding_idx=0)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (attention): ScaledDotProductAttention()\n",
      "        (w_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (w_concat): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_1): LayerNorm()\n",
      "      (ffn): PositionwiseFeedForward(\n",
      "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU()\n",
      "      )\n",
      "      (ln_2): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load pretrained model\n",
    "model = BERTTextClassifier.from_pretrained(\n",
    "    config.pretrained_path,  \n",
    "    num_frozen_layers=0,  \n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "\n",
    "### 3.1 Optimizer and Scheduler\n",
    "ScheduledOptim class is a wrapper for an optimizer that implements a learning rate scheduling strategy inspired by the Transformer paper (Attention Is All You Need). It adjusts the learning rate using a warm-up and decay mechanism to stabilize training. You can check modules/optim_schedule.py for deeper understanding.\n",
    "\n",
    "Original paper shows that they use Adam with learning rate of 1e-4, β1 = 0.9, β2 = 0.999, L2 weight decay of 0.01, learning rate warmup over the first 10,000 steps, and linear decay of the learning rate in the pretraining.\n",
    "\n",
    "For fine-tuning, most model hyperparameters are the same as in pre-training, with the exception of the batch size, learning rate, and number of training epochs.\n",
    "The dropout probability was always kept at 0.1. The optimal hyperparameter values are task-specific.\n",
    "\n",
    "\n",
    "The learing rate schedule is shown as below, where initial lr is set as 5e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import AdamW\n",
    "from modules.optim_schedule import ScheduledOptim\n",
    "import config\n",
    "\n",
    "#random create one model\n",
    "test_model = torch.nn.Linear(10, 1)\n",
    "\n",
    "\n",
    "optimizer = AdamW(test_model.parameters(), lr=config.FinetuningConfig.lr, weight_decay=config.FinetuningConfig.weight_decay)\n",
    "\n",
    "lr_values = []\n",
    "\n",
    "scheduler = ScheduledOptim(optimizer,config.warmup_steps,config.total_steps)\n",
    "\n",
    "for _ in range(config.total_steps):\n",
    "    \n",
    "    # update lr\n",
    "    scheduler.step_and_update_lr()\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    lr_values.append(lr)\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(lr_values)\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from data import load_data\n",
    "from modules.optim_schedule import ScheduledOptim\n",
    "from modules.bert import BERTTextClassifier\n",
    "import config  \n",
    "\n",
    "# finetune\n",
    "pad_idx = 0 # 填充的标记\n",
    "def split_batch(batch):  \n",
    "    tokens, attention_mask, labels = batch \n",
    "    attention_mask = (tokens != pad_idx).long()  \n",
    "    input_ids = tokens.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    return input_ids, attention_mask, labels\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "@torch.no_grad()\n",
    "def evaluate(model, clf_criterion, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_mask, gt = split_batch(batch)\n",
    "\n",
    "        clf_logits = model(input_ids)  # get classfier logits\n",
    "        \n",
    "        # print(f\"evaluate_clf_logits: {clf_logits}\")\n",
    "\n",
    "        loss = clf_criterion(clf_logits, gt)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(clf_logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(gt.cpu().numpy())\n",
    "        # get predictions and GT\n",
    "        # print(f\"Predictions: {preds.cpu().numpy()}\")\n",
    "        # print(f\"Ground Truth: {gt.cpu().numpy()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, scheduled_optimizer, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    scheduled_optimizer.zero_grad()  \n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch}\"):\n",
    "        input_ids, attention_mask, labels = split_batch(batch)\n",
    "        \n",
    "        # single sentence, requiring no segment info\n",
    "        segment_info = torch.zeros(input_ids.size(0), input_ids.size(1))\n",
    "\n",
    "        input_ids = input_ids.to(device).long()  \n",
    "        attention_mask = attention_mask.to(device).long()  \n",
    "        segment_info = segment_info.to(device).long()  \n",
    "        \n",
    "        \n",
    "        loss, logits = model(input_ids, segment_info=segment_info, labels=labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        # grad-clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # update step and lr\n",
    "        scheduled_optimizer.step_and_update_lr()  # 使用 ScheduledOptim 的 step_and_update_lr\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740d82c17cf24580904d865793c576a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/4210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7174eee37824460ea83503c29a67ac34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 0.4556, Validation Loss: 0.4504, Accuracy: 80.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ffd1c625bd47acae283a51befd9d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/4210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f0215abb314c6488f1728580d1a1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Training Loss: 0.3068, Validation Loss: 0.5671, Accuracy: 79.59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b36401c60ff44beaac0bc6345787e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/4210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a1095ecdd04c97b171ad6840fec020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Training Loss: 0.3253, Validation Loss: 0.4880, Accuracy: 80.62\n"
     ]
    }
   ],
   "source": [
    "def training_loop(model, train_dataloader, valid_dataloader, optimizer, criterion, num_epochs, warmup_steps):\n",
    "\n",
    "    scheduled_optimizer = ScheduledOptim(\n",
    "        optimizer=optimizer,\n",
    "        n_warmup_steps=warmup_steps,\n",
    "        total_steps=len(train_dataloader) * num_epochs\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        avg_train_loss = train(\n",
    "            epoch + 1, model, scheduled_optimizer, train_dataloader\n",
    "        )\n",
    "\n",
    "        # evaluate\n",
    "        avg_valid_loss, avg_acc = evaluate(model, criterion, valid_dataloader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f},\",\n",
    "            f\"Validation Loss: {avg_valid_loss:.4f}, Accuracy: {avg_acc * 100:.2f}\",\n",
    "        )\n",
    "\n",
    "        # save checkpoint\n",
    "        checkpoint_path = config.checkpoint_dir / f\"bert_clf_{epoch + 1}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": scheduled_optimizer._optimizer.state_dict(),\n",
    "                \"scheduler\": scheduled_optimizer.n_current_steps,  # 保存当前的步数\n",
    "            },\n",
    "            checkpoint_path,\n",
    "        )\n",
    "\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=config.FinetuningConfig.lr, weight_decay=config.FinetuningConfig.weight_decay)\n",
    "\n",
    "training_loop(model, train_dataloader, valid_dataloader, optimizer,torch.nn.CrossEntropyLoss(), config.FinetuningConfig.n_epoch, config.FinetuningConfig.warmup_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
